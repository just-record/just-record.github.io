---
layout: single
title: "ChatGPT - 프롬프트 엔지니어링 (prompt engineering)"
categories: ChatGPT
tag: [ChatGPT, prompt engineering]
toc: true
toc_sticky: true
toc_label: "목차"
---
## prompt engineering(프롬프트 엔지니어링)이란?

인공지능(AI) 모델, 특히 자연어 처리(NLP)를 다루는 모델에 특정 **입력 형식을 제공하여 원하는 출력을 유도하는 기술**입니다. 이 방법은 주로 대화형 AI나 언어 생성 모델에 사용되며, 사용자의 질문이나 요청을 AI가 이해하기 쉬운 방식으로 변환하여 효과적인 대답이나 결과를 얻기 위해 사용됩니다.

## 기본 원칙

### 명확하고 구체한 질문 또는 안내 작성

원하는 작업, 데이터, 출력 형식 등을 명시하고, 텍스트의 어조나 스타일도 지정해 주세요. 프롬프트가 길고 상세할수록 모델이 더 정확하고 관련된 결과를 생성할 가능성이 높습니다.

> 20세기 초 미국의 경제 상황에 대해 **500자** 내외로 요약해 줘. 이 내용은 **중학생이 이해하기 쉬운 어휘와 문장 구조**로 작성하고, **주요 산업 발전과 그 영향에 초점**을 맞춰서 설명해 줘.

### 예시와 함께 요청하기

원하는 작업의 **성공적인 실행 예시**를 제공하면, AI가 그 예시에 맞춰 일관된 스타일로 대답하도록 유도할 수 있습니다. 예시는 텍스트나 이미지 등 다양한 형태로 제공할 수 있습니다.

> 나는 신화적인 동물들에 대한 짧은 이야기를 원해. 이를 위해 다음과 같은 예시를 제공할게:  
>
> '어느 날, 한 작은 마을에 신비한 드래곤이 나타났다. 이 드래곤은 밤하늘을 밝히는 별들의 에너지를 흡수하여 마을을 보호해주었다. 하지만 어느 날, 별들이 사라지기 시작하자 마을 사람들은 드래곤과 함께 별들을 찾아 떠나는 여정을 시작했다.'
>
> 이 이야기처럼, 신화적인 동물이 주인공인 짧은 이야기를 작성해 줘. 이야기는 판타지와 모험 요소가 가미되어 있어야 해. 대략 500자 정도로 작성해 줘.

### 단계를 나눠서 요청하기

복잡한 작업의 경우, 세부적으로 필요한 단계를 나누어 정해서 알려줍니다. 예를 들어, 텍스트를 요약하고 번역하고 요약문에 있는 이름을 나열하는 작업을 요청한다면, 첫째, 둘째, 셋째로 순서대로 요청하세요.

> 다음 작업을 순차적으로 수행해 줘.
>
> 첫째, 톨스토이의 '전쟁과 평화'의 주요 줄거리를 **300자로 요약**해 줘.  
> 둘째, 이 요약문을 **영어로 번역**해 줘.  
> 셋째, 요약문에서 등장하는 주요 인물들의 **이름을 나열**해 줘

### 조건을 충족하는지 확인하기

알고 싶은 내용 중 일부에만 조건이 해당하는 경우, 어떤 결과를 알고 싶은지 명확하게 요청하세요.

> 다음의 조건을 만족하는 정보를 찾아서 알려줘.
>
> 나는 **유럽**의 주요 강들 중에서 **길이가 1000킬로미터 이상**인 강들에 대해서만 알고 싶어. 이 강들의 이름을 나열하고, 각각의 강이 흐르는 주요 국가들과 그 강의 특징을 간단히 설명해 줘. 예를 들어, 강의 길이, 주요 지류, 역사적 중요성 등에 대해 언급해 줘.

### 반복 피드백을 활용하기

모델의 응답이 만족스럽지 않을 경우, **피드백을 제공**하여 수정을 요청합니다. 이 **과정을 반복**함으로써 점점 더 정확하고 적합한 응답을 얻을 수 있습니다.

> 나는 20세기 초반 뉴욕의 건축 양식에 대한 간략한 설명을 원해. 먼저 100자 내외로 이 주제에 대해 설명해 줘.
>
> [첫 번째 피드백] - 설명이 너무 일반적임.
>
> 나는 아르누보와 아르데코 양식에 초점을 맞춘 설명을 원해.
>
> [두 번째 피드백]
>
> 대표적인 건축물 예시를 몇 개 추가해 줘

### 문맥과 목적 고려하기

요청하는 작업의 목적과 문맥을 AI에게 명확히 설명하는 것이 중요합니다. 이렇게 하면 AI가 보다 적절한 방식으로 정보를 처리하고 제공할 수 있습니다.

> 나는 **중학생**을 대상으로 한 **과학 프로젝트**를 준비하고 있어. 이 프로젝트의 목적은 **태양계의 행성들에 대한 기본적인 이해**를 돕는 것이야. 그래서 네가 도와줬으면 하는 것은, 태양계의 각 행성에 대해 쉽고 이해하기 쉬운 언어로 간단한 설명을 해주는 거야. 각 행성의 주요 특징, 크기, 거리 등을 포함시켜서 약 50자 내외로 각 행성에 대해 설명해 줘. 이 정보는 **중학생들이 과학 프로젝트에서 사용할 수 있도록 적합**해야 해

## In-context learning(인컨텍스트 러닝)

"In-context learning"은 인공지능, 특히 자연어 처리를 위한 머신러닝 모델에서 사용되는 개념입니다. 이 방식은 모델이 주어진 **프롬프트 내의 맥락을 바탕으로 학습**하고 그에 따라 **응답**을 생성하는 것을 의미합니다.

### 주요 특징

- 대량의 텍스트 데이터로 **사전 학습 지식**(언어의 기본 구조, 문맥, 다양한 주제에 대한 지식 등)을 활용합니다.
- 모델은 주어진 프롬프트의 **맥락**(예: 이야기의 연속, 질문에 대한 답변, 특정 주제에 대한 설명 등)을 **분석**하여 이에 적합한 응답을 생성합니다.
- 사용자의 프롬프트(예: 특정 스타일이나 형식을 **요구** 등)가 모델의 응답을 직접적으로 가이드합니다.

In-context learning은 모델이 새로운 특정 정보를 학습하기보다는 사전에 학습한 지식과 사용자의 입력을 통합하여, 보다 정확하고 일관된 응답을 제공하는 데 중점을 둡니다. 이 방식은 특히 복잡하고 다양한 사용자 요구에 대응하기 위한 중요한 방법입니다.

### 예시

> 다음은 세계 여러 나라의 수도에 대한 정보야.
>
> 1) 프랑스의 수도는 파리다.  
> 2) 일본의 수도는 도쿄다.  
> 3) 호주의 수도는 캔버라다.  
>
> 캐나다의 수도를 말해 줘

### Zero-shot learning(제로샷 러닝)

모델이 훈련 과정에서 **본 적 없는 새로운 데이터나 태스크에 대해 예측**을 수행하는 능력을 말합니다. 이 방식은 모델이 훈련 동안 축적한 일반 지식과 추론 능력을 활용하여 완전히 새로운 상황에 적응합니다. Zero-shot learning은 데이터가 부족하거나 다양성이 필요한 상황에서 특히 유용합니다.

> '우주 탐사'라는 주제에 대해 설명해 줘. 우주 탐사의 기본 개념, 중요성, 그리고 미래 기술의 발전 방향에 대해 200자 내외로 요약해 줘.

### One-shot learning(원샷 러닝)

모델이 **한 개의 예시**를 통해 **특정 태스크를 학습하고 수행**하는 방법입니다. 이 방식은 제한된 데이터에서도 높은 수준의 일반화와 패턴 인식 능력을 요구합니다. One-shot learning은 특히 데이터 수집이 어려운 분야에서 중요한 역할을 합니다.

> 주어진 문장: '책임감 있는 리더는 팀의 목표 달성을 위해 공정하고 윤리적인 결정을 내리며, 팀원들의 성장을 적극적으로 지원한다.' **주어진 문장을 바탕으로**, 책임감 있는 리더십의 중요성과 리더가 갖춰야 할 다른 특성에 대해 200자 내외로 추가적인 설명을 해 줘.

### Few-shot learning(퓨샷 러닝)

모델이 **소수의 예시**(보통 몇 개에서 수십 개 사이)를 통해 특정 태스크를 학습하고 수행하는 방법입니다. 이 방식은 적은 양의 데이터를 통해 모델이 빠르게 학습하고 적응할 수 있도록 설계되어 있으며, 특히 특정 도메인이나 특이한 상황에 적용됩니다.

> 다음은 서로 다른 세 가지 시나리오의 요약이야:
>
> 1. 소설에서 주인공은 시간 여행을 통해 과거를 바꾸려 한다.
> 2. 다큐멘터리는 멸종 위기에 처한 동물들을 보호하기 위한 노력을 다룬다.
> 3. 코미디 영화에서 주인공은 우연히 유명 인사가 되어 버린다.
>
> 이 **세 가지 시나리오를 바탕**으로, 새로운 시나리오 '미래의 도시에서 벌어지는 모험 이야기'를 개발해 줘. 이야기는 흥미롭고 창의적이어야 하며, 앞서 제공한 세 가지 시나리오의 요소들을 통합하거나 참고할 수 있어야 해

## Chain-of-thought

인공지능, 특히 자연어 처리 분야에서 사용되는 접근 방식으로, 문제 해결 과정에서 **중간 단계의 추론을 명시적으로 표현**하는 방법을 말합니다. 이 방식은 AI가 복잡한 문제를 해결할 때 단순히 답만을 제시하는 것이 아니라, 그 과정에서 발생하는 **생각의 연쇄**를 드러내며 답에 이르는 과정을 보여줍니다.

[논문 링크](https://arxiv.org/pdf/2201.11903.pdf)

논문에서 제시한 예시를 살펴보겠습니다.

### Standard Prompting

Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?  

A: **The answer is 11**

Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6more, how many apples do they have?

---

A: The answer is 27 (**틀린 답**)

### Chain-of-Thought Prompting

Q: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?  

A: Roger started with **5** balls. **2 cans of 3** tennis balls each is 6 tennis balls. **5 + 6 = 11**. The answer is 11.  

Q: The cafeteria had 23 apples. If they used 20 to make lunch and bought 6more, how many apples do they have?

---

A: The cafeteria started with **23** apples originally. They **used 20** to make lunch. So they had **23 - 20 = 3**. They **bought 6** more apples, so they have **3 + 6 = 9**. The answer is 9. (**맞는 답**)

## 그 외 여러가지

### 이전 대화를 기억하는가?

인공지능 모델은 **이전 대화를 기억하고 있지 않습니다**. 모델이 하나의 함수 이므로 입력 값이 함수를 거쳐서 출력 값이 나오는 것입니다. 이전 대화라는 개념이 없습니다.

**웹서비스에서는 이전 대화를 기억 하던데요?**

- 네 맞습니다. openai가 제공하는 웹서비스에서는 이전 대화 내용을 기억합니다. 웹 프로그래밍을 하여 구현한 것입니다. 모델 자체가 이전 대화를 기억하는 것은 아닙니다.
- API를 사용 해 보시면 바로 알 수 있습니다. **API를 사용하면 이전 대화를 기억하지 않습니다.** 이전 대화를 기억하게 하려면 이전의 대화와 답변도 하나의 입력으로 넣어야 합니다.
- 참고로 웹서비스도 이전 대화를 모두 기억하는 것은 아닙니다. 상황에 따라 다른 것 같습니다.

---

해시태그: #ChatGPT #prompt-engineering #인컨텍스트-러닝 #제로샷-러닝 #원샷-러닝 #퓨샷-러닝 #Chain-of-thought
