---
layout: single
title: "ChatGPT - 개요 (outline)"
categories: ChatGPT
tag: [ChatGPT, Outline]
toc: true
toc_sticky: true
toc_label: "목차"
---
ChatGPT 공식 사이트: <https://openai.com/chatgpt>

## ChatGPT?

**OpenAI**에서 개발한 인공지능 기반의 **대화형 텍스트 생성 모델**입니다. 텍스트와 코드의 방대한 데이터 세트로 훈련되어 다양한 창의적인 텍스트 형식을 생성하고, 언어를 번역하고, 다양한 종류의 창의적인 콘텐츠를 작성하고, 유익한 방식으로 질문에 답할 수 있습니다.

## 기술배경

GPT는 **'Generative Pre-trained Transformer'**의 약자 입니다.

- 'Generative'는 생성적이라는 의미
- 'Pre-trained'는 사전 훈련된 모델이라는 의미
- 'Transformer'는 트랜스포머 모델을 의미.

GPT는 트랜스포머 모델을 기반으로 사전 훈련된 생성형 모델을 의미합니다.

### Transformer

Transformer(트랜스포머)는 주로 자연어 처리(NLP)에서 사용되는 딥러닝 모델입니다.

- **Attention**(어텐션) 메커니즘: Transformer의 핵심은 'Attention'입니다. 이 메커니즘을 통해 모델은 문장 내 각 단어가 다른 단어와 어떻게 관련되어 있는지를 이해하고, **중요한 정보에 더 많은 "주의"**를 기울입니다.
- 문맥 이해: 트랜스포머는 문장 전체의 문맥을 한 번에 처리하여 각 단어의 의미를 더 정확하게 파악할 수 있습니다.
- 병렬 처리: 이 모델은 문장의 단어들을 동시에 처리할 수 있어, 기존의 순차적으로 단어를 처리하는 모델보다 효율적입니다.

### Pre-trained

인공지능 모델이 실제 작업을 수행하기 전에 이미 **대규모 데이터셋**을 사용하여 **사전에 학습**되었다는 의미입니다. 이 사전 학습 과정에서 모델은 언어, 이미지, 소리 등에 대한 광범위한 지식과 패턴을 학습합니다.

이렇게 사전에 훈련된 모델은 다양한 **특정 작업에 대해 추가적으로 학습(파인 튜닝)**될 수 있으며, 이를 통해 해당 작업에 대해 더 높은 성능을 발휘할 수 있습니다. Pre-trained 모델의 주요 장점은 학습 시간의 단축과 일반적인 작업에 대한 모델의 더 나은 이해력입니다.

## 학습과정

ChatGPT의 학습 과정은 크게 두 단계로 나눌 수 있습니다.

### 1. 사전 학습 (Pre-training)

**일반 언어 이해 능력**을 학습하는 단계

- 대규모 데이터셋 사용: ChatGPT는 인터넷에서 수집된 방대한 양의 텍스트 데이터를 사용하여 학습됩니다. 이 데이터에는 책, 기사, 웹사이트, 대화 등 다양한 형태의 텍스트가 포함됩니다.
- 언어 모델링: 이 단계에서 주요 목표는 언어의 구조를 이해하는 것입니다. 모델은 문장에서 단어가 어떻게 연결되는지, 문맥 안에서 단어의 의미는 무엇인지 등을 학습합니다.
- 자율 학습: 모델은 특정 작업에 대한 지시 없이 스스로 학습하며, 주어진 텍스트로부터 패턴과 지식을 추출합니다.
  - 비지도 학습 방법인 MMLM, NSP를 사용 하여 문장 속의 단어를 예측하고, 문장 간의 관계를 파악하는 능력을 향상시킵니다
    - MMLM (Masked Language Model): **문장의 중간 단어를 숨기고 숨긴 단어를 예측**하기
    - NSP (Next Sentence Prediction): **문장의 다음 단어를 예측**하기

### 2. 파인 튜닝 (Fine-tuning)

**특정 작업 능력**을 학습하는 단계

- 특정 작업 학습: 사전 학습된 모델을 특정 작업이나 응용 프로그램에 맞게 조정합니다. 예를 들어, 특정 유형의 대화나 주제에 대해 모델을 특화시킬 수 있습니다.
- 강화 학습: 사용자와의 상호작용을 통해 모델의 응답을 평가하고 조정합니다. 사용자 피드백을 바탕으로 모델이 더 적절하고 유용한 응답을 생성하도록 합니다.
- **인간이 개입**하여 사전 학습 된 모델의 **답에 대한 피드백을 제공**하고, 모델이 더 적절하고 유용한 응답을 생성하도록 학습합니다.

> 참고로 GPT-3.5의 파라미터 개수는 약 1,750억개로 추정됩니다.

## 주요기능(자연어 기준)

- 언어 이해 및 생성 (Language Understanding and Generation):
  - 텍스트 입력을 이해하고, 적절한 맥락과 의도에 맞는 자연스러운 언어로 응답을 생성합니다.
  - 대화 형식으로 정보를 제공하거나, 질문에 답변합니다.
- 기계 번역 (Machine Translation):
  - 다양한 언어 간의 기본적인 번역을 수행합니다.
  - 언어 간의 의미를 전달하면서도 문맥적 정확성을 유지합니다.
- 요약 (Summarization):
  - 긴 텍스트를 읽고 주요 내용을 짧고 명료한 형태로 요약합니다.
  - 중요한 정보를 간추려 전달하는 능력을 가지고 있습니다.
- 감성 분석 (Sentiment Analysis):
  - 사용자의 입력에서 감정적 톤을 파악하고, 이에 적절하게 반응합니다.
  - 긍정적, 부정적, 중립적 등의 감정 상태를 감지할 수 있습니다.
- 텍스트 분류 (Text Classification):
  - 입력된 텍스트의 종류나 주제를 분류합니다.
- 자연어 추론 (Natural Language Inference):
  - 주어진 문장이나 단락의 논리적 추론을 수행합니다.
  - 주장이나 진술의 타당성을 평가하는 데 사용됩니다.
- 개체명 인식 (Named Entity Recognition, NER):
  - 텍스트에서 사람, 장소, 조직, 날짜 등과 같은 구체적인 개체를 식별합니다.
- 의도 인식 및 대화 관리 (Intent Recognition and Dialogue Management):
  - 사용자의 의도를 파악하고, 대화 흐름을 유지하며 적절한 대응을 합니다.
  - 대화의 맥락을 이해하고 유지하는 능력이 포함됩니다.
- 문장 완성 및 자동 텍스트 생성 (Sentence Completion and Autoregressive Text Generation):
  - 주어진 문장을 기반으로 텍스트를 생성하거나 완성합니다.
  - 창의적 글쓰기, 코드 작성 등에 활용됩니다.

## 사용법

ChatGPT는 OpenAI에서 제공하는 **웹사이트**를 통해 사용 할 수 있으며 **API를 사용하면 웹사이트를 통하지 않고도** 사용 할 수 있습니다.

### 웹서비스

<https://openai.com/>에서 회원 가입을 하고 로그인을 합니다. 'ChatGPT'를 클릭합니다. <https://chat.openai.com/>로 이동하게 됩니다.

하단의 입력란에 질의를 하면 ChatGPT가 답을 합니다.

> 주요 기능

- 좌측 프레임에 그동안의 **대화 내역**이 목록으로 표시됩니다.
- 좌측 프레임의 우측 상단에 'New Chat' 버튼을 클릭하면 **새로운 대화**를 시작 할 수 있습니다.
- 좌측 프레임의 상단에 **'Explore GPTs'**를 클릭하면 GPT Store로 이동합니다. GPT Store에서는 다양한 GPT를 사용 할 수 있습니다.
- 좌측 프레임의 하단에 자신의 계정을 클릭하면 계정 정보를 확인 및 변경 할 수 있습니다.
- 좌측 프레임의 하단의 자신의 계정 바로 위를 클릭하면 'Plus'나 'Team'요금제로 upgrade 할 수 있습니다.
- 우측 프레임의 좌측 상단의 'ChatGPTxx'를 클릭하면 GPT 모델(또는 plugin으로)을 변경 할 수 있습니다.

> 주의 사항

- 질의 하는 문맥에 따라 이전 대화 내용을 기억합니다. 실제로 얼마나 기억하는지는 상황에 따라 다른 것 같습니다.
- 실제 인공지능 모델은 이전 대화 내용을 기억하지 않습니다. 웹사이트의 기능으로 보입니다.
- Hallucination(할루시네이션)이 발생합니다. Hallucination은 없는 사실을 있는 것처럼 그럴듯하게 만들어 내는 것을 의미합니다.

### API

openai에서 제공하는 API를 사용하면 웹사이트를 통하지 않고도 ChatGPT를 사용 할 수 있습니다. API를 사용하여 **자신만의 인공지능 챗봇**을 만들 수 있습니다.

- <https://platform.openai.com/docs/api-reference>: openai의 API의 사용법을 확인
- API를 사용하기 위해서는 openai에서 제공하는 API key가 필요합니다.
  - <https://platform.openai.com/api-keys>: API key를 확인 및 생성

## Hallucination(할루시네이션)

언어 생성 모델에서 "Hallucination"은 모델이 잘못된 정보를 생성하거나, 현실과 맞지 않는 사실을 '환상'처럼 만들어내는 현상을 말합니다. GPT는 Transformer 모델을 기반으로 합니다. Transformer는 **다음 단어(Token)를 예측**합니다. 이 때 **가장 확률이 높은 단어를 선택**합니다. 내용이 맞고 틀린 것을 구분하지 않고 단어의 확률을 계산합니다. 가장 그럴 듯 한 문장을 생성하므로 인간이 작성한 것 처럼 자연스럽게 보이기도 하지만 사실과 다른 내용을 생성할 수도 있습니다. 이러한 현상을 Hallucination이라고 합니다.

### Hallucination의 예

> 2024년 1월 24일 - ChatGPT4

- 질문: 한국과 중국 사이에서 일어난 대마전쟁에 대해 알려 줘
- 답변: "대마전쟁"이라고 명명된 특정한 역사적 사건은 한국과 중국의 역사에서 존재하지 않습니다. 한국과 중국 사이의 역사는 수천 년에 걸쳐 다양한 교류와 충돌이 있었지만, "대마전쟁"이라는 이름으로 특정되는 전쟁은 역사적 기록에 나타나지 않습니다. ...

> 2024년 1월 24일 - ChatGPT3.5

- 질문: 한국과 중국 사이에서 일어난 대마전쟁에 대해 알려 줘
- 답변: 대마전쟁(Da-Dong-Ah Jeonjaeng)은 대한제국(한국)과 중국 사이에서 발생한 국제 갈등과 군사 충돌을 일컫는 용어입니다. 이 대전쟁은 1894년 7월부터 1895년 4월까지 이어진 사건으로, 주로 대한제국과 중국 사이의 영토 분쟁과 권력 다툼으로 인해 발발하였습니다. 대마전쟁은 역사적으로 중요한 사건 중 하나로, 다른 국가들과의 군사적 충돌에도 영향을 미치게 되었습니다. ...

ChatGPT3.5에서는 Hallucination이 발생하네요. ChatGPT4에서 그나마 Halluciination이 적은 것 같습니다.(발생 하지 않는 것은 아닙니다.)

---

해시태그: #ChatGPt #Transformer #GPT #OpenAI #Hallucination #Pre-training #Fine-tuning #API
